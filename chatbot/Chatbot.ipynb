{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2dd82db-5eb2-47bf-ad38-0507692c5255",
   "metadata": {},
   "source": [
    "# Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cddf8bf-a68e-47f4-965d-105a057b0f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-utils\n",
      "  Obtaining dependency information for python-utils from https://files.pythonhosted.org/packages/f0/7b/e83e7b184e53530abe064b237a3731c738d3cb59f4201f3ce1a4ec0efe6f/python_utils-3.8.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading python_utils-3.8.1-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: typing-extensions>3.10.0.2 in /opt/conda/lib/python3.10/site-packages (from python-utils) (4.8.0)\n",
      "Downloading python_utils-3.8.1-py2.py3-none-any.whl (27 kB)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: python-utils\n",
      "Successfully installed python-utils-3.8.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install python-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91371c3e-f091-439b-bc5c-1be2307548c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "sys.path.append('../..')\n",
    "import python_utils\n",
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer, BertTokenizer, BertTokenizerFast, BertForSequenceClassification, AdamW\n",
    "\n",
    "# from dotenv import loader_dotenv, find_dotenv\n",
    "\n",
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c61168-fb2f-48d9-8b03-27c8fa132d0a",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d0e592a-e0e6-472b-8c62-6fd0ab44f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function receives an array of 'messages' and returns an output based on this array.\n",
    "# INPUTS:\n",
    "#      * messages: an array of messages between user and gpt model.\n",
    "#      * TODO: complete\n",
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo-16k\", temperature=0, max_tokens=500):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    last_message = response.choices[0].message\n",
    "    return last_message.content\n",
    "\n",
    "# TODO: Complete this funciton\n",
    "def get_prompt_ambig_category(user_prompt):\n",
    "    BERT_tokenizer = BertTokenizer.from_pretrained('../models/final_pretrained_saves_BERT')\n",
    "    BERT_model = BertForSequenceClassification.from_pretrained('../models/final_pretrained_saves_BERT')\n",
    "    BERT_model.eval()\n",
    "    \n",
    "    inputs = BERT_tokenizer(user_prompt, padding=True, truncation=True, return_tensors='pt')\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = BERT_model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "    query_classification = torch.argmax(probabilities, dim=1).item()\n",
    "    \n",
    "    return query_classification\n",
    "\n",
    "\n",
    "def get_prompt_rephrase(ambiguous_prompt):\n",
    "    BART_tokenizer = BartTokenizer.from_pretrained('../models/final_pretrained_saves')\n",
    "    BART_model = BartForConditionalGeneration.from_pretrained('../models/final_pretrained_saves')    \n",
    "    BART_model.eval()\n",
    "    \n",
    "    inputs = BART_tokenizer.encode(ambiguous_prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = BART_model.generate(inputs, max_length=512, num_beams=5, early_stopping=True)\n",
    "    \n",
    "    disambiguated_question = BART_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return disambiguated_question\n",
    "\n",
    "\n",
    "# TODO: Complete this funciton\n",
    "def get_content_from_database(user_prompt):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0919fba1-5275-47b2-8a46-da682d689f76",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Chatbot without Ambiguous Query Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba39e4b2-587f-4176-9f01-59b374065bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Chatbot:  Hello! How can I assist you today? \n",
      "\n",
      "-- User: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " where did Harry Potter go to school?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IS AMBIGUOUS?  1\n",
      "QUESTION IS AMBIGUOUS!\n",
      "REPHRASED QUESTION:  Where did Harry Potter go to school in Harry Potter and the Chamber of Secrets?\n",
      "-- Chatbot:  In Harry Potter and the Chamber of Secrets, Harry Potter attends Hogwarts School of Witchcraft and Wizardry. \n",
      "\n",
      "-- User: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Where did Harry Potter go to school in Harry Potter and the Goblet of Fire?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IS AMBIGUOUS?  1\n",
      "QUESTION IS AMBIGUOUS!\n",
      "REPHRASED QUESTION:  Where did Harry Potter go to school in Harry Potter and the Goblet of Fire: The Chamber of Secrets?\n",
      "-- Chatbot:  In Harry Potter and the Goblet of Fire, Harry Potter continues to attend Hogwarts School of Witchcraft and Wizardry. The Chamber of Secrets is actually the second book in the series, not the fourth. \n",
      "\n",
      "-- User: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "panels = []\n",
    "delimiter = \"~~~~\"\n",
    "start_convo_flag = True\n",
    "\n",
    "context = [{'role': 'system', 'content':f\"\"\"\n",
    "\n",
    "Just be a normal chatbot.\n",
    "\n",
    "\"\"\"}] # accumulate messages\n",
    "\n",
    "\n",
    "context.append({'role':'user', 'content':f\"{delimiter}Hi!{delimiter}\"})\n",
    "init_response = get_completion_from_messages(context)\n",
    "\n",
    "print(\"-- Chatbot: \", init_response, \"\\n\")\n",
    "while start_convo_flag:\n",
    "    print(\"-- User: \")\n",
    "    user_input = input()\n",
    "    print()\n",
    "    if user_input == \"stop\":\n",
    "        break\n",
    "        \n",
    "    # Check if conversation is an ambiguous question or not\n",
    "    is_ambiguous = get_prompt_ambig_category(user_input)\n",
    "    print(\"IS AMBIGUOUS? \", is_ambiguous)\n",
    "    \n",
    "    # conversation_history = [entry for entry in context if entry['role'] != 'system']\n",
    "    # continuation_flag = int(is_continuation(conversation_history, user_input)\n",
    "    \n",
    "    # Match question with NQ Dataset\n",
    "    db_content = get_content_from_database(user_input)\n",
    "    \n",
    "    if is_ambiguous == 1:\n",
    "        print(\"QUESTION IS AMBIGUOUS!\")\n",
    "        rephrased_user_input = get_prompt_rephrase(user_input)\n",
    "        print(\"REPHRASED QUESTION: \", rephrased_user_input)\n",
    "        user_input = rephrased_user_input\n",
    "            \n",
    "    # Add System instructions\n",
    "    context.append({'role':'system', 'content': f\"\"\"Use the provided content to answer the question.\\\n",
    "                    Do not make assumptions or use information from your pre-trained data. Use this information: {db_content}\"\"\"})\n",
    "\n",
    "    # Input User's question\n",
    "    context.append({'role': 'user', 'content': f\"{delimiter}{user_input}{delimiter}\"})\n",
    "    response = get_completion_from_messages(context)\n",
    "    print(\"-- Chatbot: \", response, \"\\n\")\n",
    "    context.append({'role': 'assistant', 'content': f\"{response}\"})\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a31bf7-d3f8-4a31-b133-7068b1166454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c988538a-b781-4fea-831d-c46630bba684",
   "metadata": {},
   "source": [
    "## Chatbot With Ambiguous Query Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc1a37-741b-4545-8c8b-f93e879e4a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c69975-3c55-4c06-9774-4e56ea1a8079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
