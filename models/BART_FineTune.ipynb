{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca83e55d-a5c0-4c1a-abd0-ff6f25a9e42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/tobysavage/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/tobysavage/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor, nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer, AdamW\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec26010b-84d8-455d-9c01-bd8b958b426f",
   "metadata": {},
   "source": [
    "Read in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03de6f23-de7e-4fa9-be03-80525073912c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_light.json\n",
      "ambignq_light.zip\n",
      "ambig_disambig_dev.csv\n",
      "ambig_disambig_train.csv\n",
      "ambig_disambig_dev_full.csv\n",
      "LICENSE\n",
      "dev_light.json\n",
      "ambig_disambig_dest.csv\n",
      "ambig_disambig_test.csv\n"
     ]
    }
   ],
   "source": [
    "# Get the directory you want to list files from\n",
    "directory = '../../data/LIGHT'\n",
    "\n",
    "# List all files and directories in the specified directory\n",
    "for filename in os.listdir(directory):\n",
    "    if os.path.isfile(os.path.join(directory, filename)):\n",
    "        print(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22d33854-9936-429f-93a2-3543f9183984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ambiguous_question</th>\n",
       "      <th>disambiguated_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did the simpsons first air on television?</td>\n",
       "      <td>When did the Simpsons first air on television ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When did the simpsons first air on television?</td>\n",
       "      <td>When did the Simpsons first air as a half-hour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the legal age of marriage in usa?</td>\n",
       "      <td>What is the legal age of marriage, without par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the legal age of marriage in usa?</td>\n",
       "      <td>What is the legal age of marriage, without par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the legal age of marriage in usa?</td>\n",
       "      <td>What is the legal age of marriage, without par...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ambiguous_question  \\\n",
       "0  When did the simpsons first air on television?   \n",
       "1  When did the simpsons first air on television?   \n",
       "2       What is the legal age of marriage in usa?   \n",
       "3       What is the legal age of marriage in usa?   \n",
       "4       What is the legal age of marriage in usa?   \n",
       "\n",
       "                              disambiguated_question  \n",
       "0  When did the Simpsons first air on television ...  \n",
       "1  When did the Simpsons first air as a half-hour...  \n",
       "2  What is the legal age of marriage, without par...  \n",
       "3  What is the legal age of marriage, without par...  \n",
       "4  What is the legal age of marriage, without par...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../../data/LIGHT/ambig_disambig_train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04d5cf6b-df5c-4759-bacc-a96c6a8f7260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ambiguous_question</th>\n",
       "      <th>disambiguated_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is the statue of liberty supposed to be?</td>\n",
       "      <td>Who is the statue of liberty in Leicester supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who is the statue of liberty supposed to be?</td>\n",
       "      <td>Who is the statue of liberty in Seattle suppos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who conducted a 300 mile march to sacramento c...</td>\n",
       "      <td>Who is the individual that was the leader of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who conducted a 300 mile march to sacramento c...</td>\n",
       "      <td>Who is the group that organized a strike and 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When was i'll be home for christmas released?</td>\n",
       "      <td>When was the song \"I'll Be Home for Christmas\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  ambiguous_question  \\\n",
       "0       Who is the statue of liberty supposed to be?   \n",
       "1       Who is the statue of liberty supposed to be?   \n",
       "2  Who conducted a 300 mile march to sacramento c...   \n",
       "3  Who conducted a 300 mile march to sacramento c...   \n",
       "4      When was i'll be home for christmas released?   \n",
       "\n",
       "                              disambiguated_question  \n",
       "0  Who is the statue of liberty in Leicester supp...  \n",
       "1  Who is the statue of liberty in Seattle suppos...  \n",
       "2  Who is the individual that was the leader of a...  \n",
       "3  Who is the group that organized a strike and 3...  \n",
       "4  When was the song \"I'll Be Home for Christmas\"...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev = pd.read_csv('../../data/LIGHT/ambig_disambig_dev.csv')\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9d85822-5ec3-4fa5-8275-d1208f7f5e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ambiguous_question</th>\n",
       "      <th>disambiguated_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why did the st louis cardinals move to arizona?</td>\n",
       "      <td>What ability caused the st louis cardinals mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why did the st louis cardinals move to arizona?</td>\n",
       "      <td>What physical issue caused the st louis cardin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why did the st louis cardinals move to arizona?</td>\n",
       "      <td>What fan issue caused the st louis cardinals m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who is the current chairman of african union c...</td>\n",
       "      <td>Who is the 4th chairman of african union commi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who is the current chairman of african union c...</td>\n",
       "      <td>Who is the 3rd chairman of african union commi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  ambiguous_question  \\\n",
       "0    Why did the st louis cardinals move to arizona?   \n",
       "1    Why did the st louis cardinals move to arizona?   \n",
       "2    Why did the st louis cardinals move to arizona?   \n",
       "3  Who is the current chairman of african union c...   \n",
       "4  Who is the current chairman of african union c...   \n",
       "\n",
       "                              disambiguated_question  \n",
       "0  What ability caused the st louis cardinals mov...  \n",
       "1  What physical issue caused the st louis cardin...  \n",
       "2  What fan issue caused the st louis cardinals m...  \n",
       "3  Who is the 4th chairman of african union commi...  \n",
       "4  Who is the 3rd chairman of african union commi...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('../../data/LIGHT/ambig_disambig_test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54108478-e3a8-4cce-a2f3-4f888026ea2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ambiguous_question</th>\n",
       "      <th>disambiguated_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why did the st louis cardinals move to arizona?</td>\n",
       "      <td>What ability caused the st louis cardinals mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why did the st louis cardinals move to arizona?</td>\n",
       "      <td>What physical issue caused the st louis cardin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why did the st louis cardinals move to arizona?</td>\n",
       "      <td>What fan issue caused the st louis cardinals m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who is the current chairman of african union c...</td>\n",
       "      <td>Who is the 4th chairman of african union commi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who is the current chairman of african union c...</td>\n",
       "      <td>Who is the 3rd chairman of african union commi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  ambiguous_question  \\\n",
       "0    Why did the st louis cardinals move to arizona?   \n",
       "1    Why did the st louis cardinals move to arizona?   \n",
       "2    Why did the st louis cardinals move to arizona?   \n",
       "3  Who is the current chairman of african union c...   \n",
       "4  Who is the current chairman of african union c...   \n",
       "\n",
       "                              disambiguated_question  \n",
       "0  What ability caused the st louis cardinals mov...  \n",
       "1  What physical issue caused the st louis cardin...  \n",
       "2  What fan issue caused the st louis cardinals m...  \n",
       "3  Who is the 4th chairman of african union commi...  \n",
       "4  Who is the 3rd chairman of african union commi...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_full = pd.read_csv('../../data/LIGHT/ambig_disambig_dev_full.csv')\n",
    "df_dev_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0942628c-3dbe-4bf2-bd9c-aef5bee8158a",
   "metadata": {},
   "source": [
    "Model Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddd3f04c-abe5-4281-abca-b56492703461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50265, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "# Load pre-trained model\n",
    "# model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
    "model.config.dropout = 0.1\n",
    "\n",
    "# move the model to the GPU\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d5cf277-a3bf-4a67-be7c-49e3dff3335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = list(df_train['ambiguous_question'])\n",
    "targets_train = list(df_train['disambiguated_question'])\n",
    "\n",
    "# Tokenize inputs and targets\n",
    "inputs_train = tokenizer(inputs_train, padding=True, truncation=True, return_tensors='pt')\n",
    "targets_train = tokenizer(targets_train, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd04869b-e81a-4842-9003-7149db1c800a",
   "metadata": {},
   "source": [
    "Convert Dataset to PyTorch Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c802d62-52a2-498f-b12f-ad5f1c8ca25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmbigNQDataset(Dataset):\n",
    "    def __init__(self, encodings, resultings):\n",
    "        self.encodings = encodings\n",
    "        self.resultings = resultings\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.resultings['input_ids'][idx]\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.resultings['input_ids'])\n",
    "    \n",
    "dataset_train = AmbigNQDataset(inputs_train, targets_train)\n",
    "loader_train = DataLoader(dataset_train, batch_size = 10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdc2cf12-1d9b-4f10-8f17-afd2075754d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_dev = list(df_dev['ambiguous_question'])\n",
    "targets_dev = list(df_dev['disambiguated_question'])\n",
    "\n",
    "# Tokenize inputs and targets\n",
    "inputs_dev = tokenizer(inputs_dev, padding=True, truncation=True, return_tensors='pt')\n",
    "targets_dev = tokenizer(targets_dev, padding=True, truncation=True, return_tensors='pt')\n",
    "dataset_dev = AmbigNQDataset(inputs_dev, targets_dev)\n",
    "loader_dev = DataLoader(dataset_dev, batch_size = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ecbba31-cdd1-4d6c-85d5-93870a463321",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test = list(df_test['ambiguous_question'])\n",
    "targets_test = list(df_test['disambiguated_question'])\n",
    "\n",
    "# Tokenize inputs and targets\n",
    "inputs_test = tokenizer(inputs_test, padding=True, truncation=True, return_tensors='pt')\n",
    "targets_test = tokenizer(targets_test, padding=True, truncation=True, return_tensors='pt')\n",
    "dataset_test = AmbigNQDataset(inputs_test, targets_test)\n",
    "loader_test = DataLoader(dataset_test, batch_size = 10, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "742bc43c-3c78-46ce-8bad-2ebcc693a436",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_dev_full = list(df_dev_full['ambiguous_question'])\n",
    "targets_dev_full = list(df_dev_full['disambiguated_question'])\n",
    "\n",
    "# Tokenize inputs and targets\n",
    "inputs_dev_full = tokenizer(inputs_dev_full, padding=True, truncation=True, return_tensors='pt')\n",
    "targets_dev_full = tokenizer(targets_dev_full, padding=True, truncation=True, return_tensors='pt')\n",
    "dataset_dev_full = AmbigNQDataset(inputs_dev_full, targets_dev_full)\n",
    "loader_dev_full = DataLoader(dataset_dev_full, batch_size = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241351d9-5273-41aa-a66e-c8889b9b73ae",
   "metadata": {},
   "source": [
    "Fine-Tuning BART-Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0374bce7-443f-4acc-910a-98c6781789e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c5bb48e-ac3f-481f-b802-7ae8b5e8b320",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "# print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373578d6-ce80-4295-a679-782391c858ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained BART-Large model for fine-tuning\n",
    "epochs = 5\n",
    "# model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
    "\n",
    "# Early Stopping Parameters\n",
    "patience = 2\n",
    "min_delta = 0.001\n",
    "best_val_loss = np.inf\n",
    "patience_counter = 0\n",
    "\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "# training loop\n",
    "model.train() # put model in train mode\n",
    "for epoch in range(epochs):\n",
    "    total_train_loss = 0\n",
    "    for batch in loader_train:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to('cuda')\n",
    "        attention_mask = batch['attention_mask'].to('cuda')\n",
    "        resultings = batch['labels'].to('cuda')\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=resultings)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss +=loss.item()\n",
    "        \n",
    "    avg_train_loss = total_train_loss / len(loader_train)\n",
    "    training_losses.append(avg_train_loss)\n",
    "    print(f\"Epoch: {epoch}, Training Loss: {avg_train_loss}\")\n",
    "    \n",
    "    \n",
    "    # Validation Step\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader_dev:\n",
    "            input_ids = batch['input_ids'].to('cuda')\n",
    "            attention_mask = batch['attention_mask'].to('cuda')\n",
    "            labels = batch['labels'].to('cuda')\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            total_val_loss += loss.item()\n",
    "    avg_val_loss = total_val_loss/len(loader_dev)\n",
    "    validation_losses.append(avg_val_loss)\n",
    "    print(f\"Epoch: {epoch}, Validation Loss: {avg_val_loss}\")\n",
    "    \n",
    "    # Early Stopping Check\n",
    "    if avg_val_loss + min_delta < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0  # reset counter if improvement is found\n",
    "    else:\n",
    "        patience_counter += 1  # increment counter if no improvement\n",
    "\n",
    "    # Break the loop if patience is exceeded\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Stopping early due to no improvement in validation loss.\")\n",
    "        break\n",
    "    \n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72ce661d-7169-40ba-9dbf-c62023d62b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cpu_training_loss = [loss_item.item() for loss_item in training_losses]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.plot(training_losses, label='Training Loss')\n",
    "plt.plot(validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8ddbb87-1316-4b71-83f2-7a0eadac78ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "\"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Why did the st louis cardinals move to arizona in 2016?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m bleu_score \u001b[38;5;241m=\u001b[39m corpus_bleu(tokenized_references, tokenized_predictions)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Calculate METEOR score\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m meteor_scores \u001b[38;5;241m=\u001b[39m [meteor_score([ref], pred) \u001b[38;5;28;01mfor\u001b[39;00m ref, pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(references, predictions)]\n\u001b[1;32m     42\u001b[0m average_meteor_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(meteor_scores) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(meteor_scores)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorpus BLEU Score on Test Set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbleu_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[22], line 41\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m bleu_score \u001b[38;5;241m=\u001b[39m corpus_bleu(tokenized_references, tokenized_predictions)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Calculate METEOR score\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m meteor_scores \u001b[38;5;241m=\u001b[39m [\u001b[43mmeteor_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mref\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ref, pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(references, predictions)]\n\u001b[1;32m     42\u001b[0m average_meteor_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(meteor_scores) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(meteor_scores)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorpus BLEU Score on Test Set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbleu_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/translate/meteor_score.py:397\u001b[0m, in \u001b[0;36mmeteor_score\u001b[0;34m(references, hypothesis, preprocess, stemmer, wordnet, alpha, beta, gamma)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeteor_score\u001b[39m(\n\u001b[1;32m    348\u001b[0m     references: Iterable[Iterable[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m    349\u001b[0m     hypothesis: Iterable[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m     gamma: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m    356\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m    Calculates METEOR score for hypothesis with multiple references as\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m    described in \"Meteor: An Automatic Metric for MT Evaluation with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;124;03m    :return: The sentence-level METEOR score.\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43msingle_meteor_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhypothesis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstemmer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstemmer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwordnet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwordnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m            \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/translate/meteor_score.py:398\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeteor_score\u001b[39m(\n\u001b[1;32m    348\u001b[0m     references: Iterable[Iterable[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m    349\u001b[0m     hypothesis: Iterable[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m     gamma: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m    356\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m    Calculates METEOR score for hypothesis with multiple references as\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m    described in \"Meteor: An Automatic Metric for MT Evaluation with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;124;03m    :return: The sentence-level METEOR score.\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m--> 398\u001b[0m         \u001b[43msingle_meteor_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhypothesis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstemmer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstemmer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwordnet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwordnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m            \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m reference \u001b[38;5;129;01min\u001b[39;00m references\n\u001b[1;32m    409\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/translate/meteor_score.py:326\u001b[0m, in \u001b[0;36msingle_meteor_score\u001b[0;34m(reference, hypothesis, preprocess, stemmer, wordnet, alpha, beta, gamma)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msingle_meteor_score\u001b[39m(\n\u001b[1;32m    283\u001b[0m     reference: Iterable[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    284\u001b[0m     hypothesis: Iterable[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    290\u001b[0m     gamma: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m    291\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    Calculates METEOR score for single hypothesis and reference as per\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    \"Meteor: An Automatic Metric for MT Evaluation with HighLevels of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    :return: The sentence-level METEOR score.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     enum_hypothesis, enum_reference \u001b[38;5;241m=\u001b[39m \u001b[43m_generate_enums\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhypothesis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m     translation_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(enum_hypothesis)\n\u001b[1;32m    330\u001b[0m     reference_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(enum_reference)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/translate/meteor_score.py:33\u001b[0m, in \u001b[0;36m_generate_enums\u001b[0;34m(hypothesis, reference, preprocess)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03mTakes in pre-tokenized inputs for hypothesis and reference and returns\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03menumerated word lists for each of them\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m:return: enumerated words list\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(hypothesis, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhypothesis\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expects pre-tokenized hypothesis (Iterable[str]): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhypothesis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     35\u001b[0m     )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(reference, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreference\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expects pre-tokenized reference (Iterable[str]): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreference\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     40\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Why did the st louis cardinals move to arizona in 2016?"
     ]
    }
   ],
   "source": [
    "model.eval()  # make sure the model is in evaluation mode\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader_test:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # Generate the outputs using the model\n",
    "        outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Decode predictions\n",
    "        pred_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        # print(\"BATCH: \", batch)\n",
    "        # print(\"PREDS: \", pred_texts)\n",
    "        predictions.extend(pred_texts)\n",
    "        \n",
    "        # Decode the reference labels\n",
    "        ref_texts = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)\n",
    "        # Here, we assume that each entry in the batch has only one reference\n",
    "        \n",
    "        input_texts = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
    "        \n",
    "        # for i in range(len(pred_texts)):  # Assuming batch size is not larger than the number of samples\n",
    "        #     print(f\"INPUT: {input_texts[i]}\")\n",
    "        #     print(f\"ACTUAL: {ref_texts[i]}\")\n",
    "        #     print(f\"PREDICTION: {pred_texts[i]}\")\n",
    "        #     print(\"\\n\")  # Adds a newline for better readability\n",
    "        \n",
    "        references.extend([[ref] for ref in ref_texts])\n",
    "        # break\n",
    "\n",
    "# Tokenize the predictions and references\n",
    "tokenized_predictions = [nltk.word_tokenize(pred) for pred in predictions]\n",
    "tokenized_references = [[nltk.word_tokenize(ref[0])] for ref in references]  # BLEU expects a list of references\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu(tokenized_references, tokenized_predictions)\n",
    "\n",
    "# Calculate METEOR score\n",
    "meteor_scores = [meteor_score([ref], pred) for ref, pred in zip(references, predictions)]\n",
    "average_meteor_score = sum(meteor_scores) / len(meteor_scores)\n",
    "\n",
    "print(f\"Corpus BLEU Score on Test Set: {bleu_score}\")\n",
    "print(f\"Average METEOR Score on Test Set: {average_meteor_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc76943-0c37-4673-bd7a-f3e5d1d21d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1864d92-ee67-4ae3-8ffd-46c66f27dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpu_training_loss = [loss_item.item() for loss_item in training_loss]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.title(\"Training Loss\")\n",
    "# plt.plot(cpu_training_loss, label=\"Training\")\n",
    "# plt.xlabel(\"Iteration\")\n",
    "# plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f67ba16-2f76-4cab-8147-116ade77de84",
   "metadata": {},
   "source": [
    "Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fa29f26-b617-4cac-bbe1-ef675d244127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pretrained_saves/tokenizer_config.json',\n",
       " 'pretrained_saves/special_tokens_map.json',\n",
       " 'pretrained_saves/vocab.json',\n",
       " 'pretrained_saves/merges.txt',\n",
       " 'pretrained_saves/added_tokens.json')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('pretrained_saves')\n",
    "tokenizer.save_pretrained('pretrained_saves')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e588f99-0a69-4964-9aa5-ce3324cc5c23",
   "metadata": {},
   "source": [
    "Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4dda5e9-d1fa-48eb-887a-1c3f3e6dfa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BartForConditionalGeneration.from_pretrained('pretrained_saves').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f9841b2-c6eb-4ac0-966a-3615c1fb88ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: Why did the st louis cardinals move to arizona?\n",
      "ACTUAL: What ability caused the st louis cardinals move to arizona?\n",
      "PREDICTION: Why did the st louis cardinals move to arizona in 2016?\n",
      "\n",
      "\n",
      "INPUT: Why did the st louis cardinals move to arizona?\n",
      "ACTUAL: What physical issue caused the st louis cardinals move to arizona?\n",
      "PREDICTION: Why did the st louis cardinals move to arizona in 2016?\n",
      "\n",
      "\n",
      "INPUT: Why did the st louis cardinals move to arizona?\n",
      "ACTUAL: What fan issue caused the st louis cardinals move to arizona?\n",
      "PREDICTION: Why did the st louis cardinals move to arizona in 2016?\n",
      "\n",
      "\n",
      "INPUT: Who is the current chairman of african union commission?\n",
      "ACTUAL: Who is the 4th chairman of african union commission?\n",
      "PREDICTION: Who is the 12th chairman of african union commission?\n",
      "\n",
      "\n",
      "INPUT: Who is the current chairman of african union commission?\n",
      "ACTUAL: Who is the 3rd chairman of african union commission?\n",
      "PREDICTION: Who is the 12th chairman of african union commission?\n",
      "\n",
      "\n",
      "INPUT: Who is the current chairman of african union commission?\n",
      "ACTUAL: Who is the 2nd chairman of african union commission?\n",
      "PREDICTION: Who is the 12th chairman of african union commission?\n",
      "\n",
      "\n",
      "INPUT: Who is the current chairman of african union commission?\n",
      "ACTUAL: Who became the chairman of african union commission in 2017?\n",
      "PREDICTION: Who is the 12th chairman of african union commission?\n",
      "\n",
      "\n",
      "INPUT: Who is the current chairman of african union commission?\n",
      "ACTUAL: Who became the chairman of african union commission in 2012?\n",
      "PREDICTION: Who is the 12th chairman of african union commission?\n",
      "\n",
      "\n",
      "INPUT: Who is the current chairman of african union commission?\n",
      "ACTUAL: Who became the chairman of african union commission in 2008?\n",
      "PREDICTION: Who is the 12th chairman of african union commission?\n",
      "\n",
      "\n",
      "INPUT: Who won the final hoh big brother 20?\n",
      "ACTUAL: Who won the Final HoH in the American reality show Big Brother 20?\n",
      "PREDICTION: Who won the final season of hoh big brother 20?\n",
      "\n",
      "\n",
      "INPUT: Who won the final hoh big brother 20?\n",
      "ACTUAL: Who won the final vote in the British reality show Celebrity Big Brother 20?\n",
      "PREDICTION: Who won the final season of hoh big brother 20?\n",
      "\n",
      "\n",
      "INPUT: How long do contestants get to answer on jeopardy?\n",
      "ACTUAL: How long do contestants get to answer a typical question on jeopardy?\n",
      "PREDICTION: How long do contestants get to answer on jeopardy in season 1?\n",
      "\n",
      "\n",
      "INPUT: How long do contestants get to answer on jeopardy?\n",
      "ACTUAL: How long do contestants get to answer a final jeopardy question on jeopardy?\n",
      "PREDICTION: How long do contestants get to answer on jeopardy in season 1?\n",
      "\n",
      "\n",
      "INPUT: How long do contestants get to answer on jeopardy?\n",
      "ACTUAL: How long do contestants get to answer on jeopardy's online test?\n",
      "PREDICTION: How long do contestants get to answer on jeopardy in season 1?\n",
      "\n",
      "\n",
      "INPUT: How long do contestants get to answer on jeopardy?\n",
      "ACTUAL: How long do contestants have to answer during the first two rounds of Jeopardy!?\n",
      "PREDICTION: How long do contestants get to answer on jeopardy in season 1?\n",
      "\n",
      "\n",
      "INPUT: How long do contestants get to answer on jeopardy?\n",
      "ACTUAL: How long do contestants have to answer during the last round of Jeopardy!?\n",
      "PREDICTION: How long do contestants get to answer on jeopardy in season 1?\n",
      "\n",
      "\n",
      "INPUT: Who took control of the italian government in 1922?\n",
      "ACTUAL: What party took control of the Italian government in 1922?\n",
      "PREDICTION: Who took control of the italian government in 1922?\n",
      "\n",
      "\n",
      "INPUT: Who took control of the italian government in 1922?\n",
      "ACTUAL: What leader took control of the Italian government in 1922?\n",
      "PREDICTION: Who took control of the italian government in 1922?\n",
      "\n",
      "\n",
      "INPUT: Who took control of the italian government in 1922?\n",
      "ACTUAL: What faction took control of the Italian government in 1922?\n",
      "PREDICTION: Who took control of the italian government in 1922?\n",
      "\n",
      "\n",
      "INPUT: Who took control of the italian government in 1922?\n",
      "ACTUAL: Who is the party that took control of the italian government in 1922?\n",
      "PREDICTION: Who took control of the italian government in 1922?\n",
      "\n",
      "\n",
      "INPUT: Who took control of the italian government in 1922?\n",
      "ACTUAL: Who is the prime minister that took control of the italian government in 1922?\n",
      "PREDICTION: Who took control of the italian government in 1922?\n",
      "\n",
      "\n",
      "INPUT: Where was 'top of the lake' filmed?\n",
      "ACTUAL: Where was season 1 of  'top of the lake' filmed almost entirely?\n",
      "PREDICTION: Where was the film 'Top of the Lake' filmed?\n",
      "\n",
      "\n",
      "INPUT: Where was 'top of the lake' filmed?\n",
      "ACTUAL: Where were the scenes in the women's commune in season 1 of 'top of the lake' filmed?\n",
      "PREDICTION: Where was the film 'Top of the Lake' filmed?\n",
      "\n",
      "\n",
      "INPUT: Where was 'top of the lake' filmed?\n",
      "ACTUAL: Where was season 2 of 'top of the lake' filmed?\n",
      "PREDICTION: Where was the film 'Top of the Lake' filmed?\n",
      "\n",
      "\n",
      "INPUT: Where was 'top of the lake' filmed?\n",
      "ACTUAL: Where was the original 'top of the lake' filmed except for the women's commune?\n",
      "PREDICTION: Where was the film 'Top of the Lake' filmed?\n",
      "\n",
      "\n",
      "INPUT: Where was 'top of the lake' filmed?\n",
      "ACTUAL: Where was the original 'top of the lake' filmed for the women's commune?\n",
      "PREDICTION: Where was the film 'Top of the Lake' filmed?\n",
      "\n",
      "\n",
      "INPUT: Where was 'top of the lake' filmed?\n",
      "ACTUAL: Where was 'top of the lake: China Girl' filmed?\n",
      "PREDICTION: Where was the film 'Top of the Lake' filmed?\n",
      "\n",
      "\n",
      "INPUT: How many seconds do you have to throw a grenade?\n",
      "ACTUAL: How many seconds did you have to throw the first World War I fragmentation grenades?\n",
      "PREDICTION: How many seconds do you have to throw a grenade in the US?\n",
      "\n",
      "\n",
      "INPUT: How many seconds do you have to throw a grenade?\n",
      "ACTUAL: How many seconds did you have to throw the updated World War I fragmentation grenades?\n",
      "PREDICTION: How many seconds do you have to throw a grenade in the US?\n",
      "\n",
      "\n",
      "INPUT: How many seconds do you have to throw a grenade?\n",
      "ACTUAL: How many seconds did you have to throw a WWI stick grenade?\n",
      "PREDICTION: How many seconds do you have to throw a grenade in the US?\n",
      "\n",
      "\n",
      "INPUT: How many seconds do you have to throw a grenade?\n",
      "ACTUAL: How many seconds do you have to throw a US ET-MP grenade?\n",
      "PREDICTION: How many seconds do you have to throw a grenade in the US?\n",
      "\n",
      "\n",
      "INPUT: How many seconds do you have to throw a grenade?\n",
      "ACTUAL: How many seconds was the delay of the Mills bomb grenade before explosion prior to 1940?\n",
      "PREDICTION: How many seconds do you have to throw a grenade in the US?\n",
      "\n",
      "\n",
      "INPUT: How many seconds do you have to throw a grenade?\n",
      "ACTUAL: How many seconds was the delay of the Mills bomb grenade before explosion after 1940?\n",
      "PREDICTION: How many seconds do you have to throw a grenade in the US?\n",
      "\n",
      "\n",
      "INPUT: How many seconds do you have to throw a grenade?\n",
      "ACTUAL: How seconds was the delay of WWII era thermite?\n",
      "PREDICTION: How many seconds do you have to throw a grenade in the US?\n",
      "\n",
      "\n",
      "INPUT: How many jimmy john's are there in the world?\n",
      "ACTUAL: How many jimmy john's are there in the world as of October 2018?\n",
      "PREDICTION: How many jimmy john's are there in the world as of 2015?\n",
      "\n",
      "\n",
      "INPUT: How many jimmy john's are there in the world?\n",
      "ACTUAL: How many jimmy john's are there in the world in 2010?\n",
      "PREDICTION: How many jimmy john's are there in the world as of 2015?\n",
      "\n",
      "\n",
      "INPUT: How many jimmy john's are there in the world?\n",
      "ACTUAL: How many jimmy john's are there in the world in 2007?\n",
      "PREDICTION: How many jimmy john's are there in the world as of 2015?\n",
      "\n",
      "\n",
      "INPUT: How many jimmy john's are there in the world?\n",
      "ACTUAL: How many jimmy john's are there plans for in the world?\n",
      "PREDICTION: How many jimmy john's are there in the world as of 2015?\n",
      "\n",
      "\n",
      "INPUT: Who defeated the new york jets on the first televised monday night football game?\n",
      "ACTUAL: Who was the team who defeated the new york jets on the first televised monday night football game?\n",
      "PREDICTION: Who defeated the New York Jets in the first televised Monday night football game?\n",
      "\n",
      "\n",
      "INPUT: Who defeated the new york jets on the first televised monday night football game?\n",
      "ACTUAL: Who was the coach defeated the new york jets on the first televised monday night football game?\n",
      "PREDICTION: Who defeated the New York Jets in the first televised Monday night football game?\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Generate the outputs using the model\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Decode predictions\u001b[39;00m\n\u001b[1;32m     13\u001b[0m pred_texts \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(outputs, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1752\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1746\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1747\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   1748\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1750\u001b[0m     )\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# 13. run beam search\u001b[39;00m\n\u001b[0;32m-> 1752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1761\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1762\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1763\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE:\n\u001b[1;32m   1766\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m     logits_warper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:3144\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3141\u001b[0m next_tokens \u001b[38;5;241m=\u001b[39m next_tokens \u001b[38;5;241m%\u001b[39m vocab_size\n\u001b[1;32m   3143\u001b[0m \u001b[38;5;66;03m# stateless\u001b[39;00m\n\u001b[0;32m-> 3144\u001b[0m beam_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mbeam_scorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3145\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_token_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3150\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeam_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeam_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3154\u001b[0m beam_scores \u001b[38;5;241m=\u001b[39m beam_outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_beam_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3155\u001b[0m beam_next_tokens \u001b[38;5;241m=\u001b[39m beam_outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_beam_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:269\u001b[0m, in \u001b[0;36mBeamSearchScorer.process\u001b[0;34m(self, input_ids, next_scores, next_tokens, next_indices, pad_token_id, eos_token_id, beam_indices, group_index)\u001b[0m\n\u001b[1;32m    267\u001b[0m batch_beam_idx \u001b[38;5;241m=\u001b[39m batch_idx \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_size \u001b[38;5;241m+\u001b[39m next_index\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# add to generated hypotheses if end of sentence\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (eos_token_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[43mnext_token\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01min\u001b[39;00m eos_token_id):\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;66;03m# if beam_token does not belong to top num_beams tokens, it should not be added\u001b[39;00m\n\u001b[1;32m    271\u001b[0m     is_beam_token_worse_than_top_num_beams \u001b[38;5;241m=\u001b[39m beam_token_rank \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_size\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_beam_token_worse_than_top_num_beams:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()  # make sure the model is in evaluation mode\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader_test:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # Generate the outputs using the model\n",
    "        outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Decode predictions\n",
    "        pred_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        # print(pred_texts)\n",
    "        predictions.extend(pred_texts)\n",
    "        \n",
    "        # Decode the reference labels\n",
    "        ref_texts = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)\n",
    "        input_texts = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
    "        \n",
    "        for i in range(len(pred_texts)):  # Assuming batch size is not larger than the number of samples\n",
    "            print(f\"INPUT: {input_texts[i]}\")\n",
    "            print(f\"ACTUAL: {ref_texts[i]}\")\n",
    "            print(f\"PREDICTION: {pred_texts[i]}\")\n",
    "            print(\"\\n\")  # Adds a newline for better readability\n",
    "        \n",
    "        # Here, we assume that each entry in the batch has only one reference\n",
    "        references.extend([[ref] for ref in ref_texts])\n",
    "        # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18d76ad7-0961-4a4d-846b-aee26dd304ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus BLEU Score on Test Set: 0.4049434569729642\n",
      "Average METEOR Score on Test Set: 0.6872554545833018\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the predictions and references\n",
    "tokenized_predictions = [nltk.word_tokenize(pred) for pred in predictions]\n",
    "tokenized_references = [[nltk.word_tokenize(ref[0])] for ref in references]  # BLEU expects a list of references\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu(tokenized_references, tokenized_predictions)\n",
    "\n",
    "# Calculate METEOR score\n",
    "meteor_scores = [meteor_score(refs, preds) for refs, preds in zip(tokenized_references, tokenized_predictions)]\n",
    "average_meteor_score = sum(meteor_scores) / len(meteor_scores)\n",
    "\n",
    "print(f\"Corpus BLEU Score on Test Set: {bleu_score}\")\n",
    "print(f\"Average METEOR Score on Test Set: {average_meteor_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1074dd-4df3-41e2-bdea-42ce268fdbb0",
   "metadata": {},
   "source": [
    "TODO: Only save model when dev_loss starts going up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84466844-facc-4db9-b5f6-413b5b0c9622",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
